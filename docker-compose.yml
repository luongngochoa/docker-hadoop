version: '3.3'

services:
  namenode:
    image: hoaln/hadoop-namenode:3.2.2-java8
    container_name: namenode
    hostname: namenode
    # hostname: "172.20.0.6"
    networks:
      frontend:
        ipv4_address: 172.20.0.6
    ports:
      - 9000:9000 # Namenode RPC for HDFS clients
      - 9870:9870 # WebUI - dfs.namenode.http-address
    volumes:
      - /data/container_data/namenode:/hadoop/dfs/name
      - /tmp:/tmp
    environment:
      - CLUSTER_NAME=HADOOP
    env_file:
      - ./hadoop.env

  datanode:
    image: hoaln/hadoop-datanode:3.2.2-java8
    container_name: datanode
    # hostname: "172.20.0.7"
    networks:
      frontend:
        ipv4_address: 172.20.0.7
    volumes:
      - /data/container_data/datanode:/hadoop/dfs/data
    environment:
      SERVICE_PRECONDITION: "namenode:9870"
    env_file:
      - ./hadoop.env
    ports:
      - 9864:9864  # WebUI - dfs.datanode.http.address
      - 9866:9866  # Data transfer - dfs.datanode.address

  resourcemanager:
    image: hoaln/hadoop-resourcemanager:3.2.2-java8
    container_name: resourcemanager
    hostname: "resourcemanager"
    # hostname: "172.20.0.8"
    restart: always
    networks:
      frontend:
        ipv4_address: 172.20.0.8
    ports:
     - 8088:8088
    environment:
      SERVICE_PRECONDITION: "namenode:9870 historyserver:8188"
    env_file:
      - ./hadoop.env

  nodemanager:
    image: hoaln/hadoop-nodemanager:3.2.2-java8
    container_name: nodemanager
    restart: always
    networks:
      frontend:
        ipv4_address: 172.20.0.9
    ports:
      - 8042:8042
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864 resourcemanager:8088"
    env_file:
      - ./hadoop.env

  historyserver:
    image: hoaln/hadoop-historyserver:3.2.2-java8
    container_name: historyserver
    hostname: historyserver
    restart: always
    networks:
      frontend:
        ipv4_address: 172.20.0.10
    ports:
      - 8188:8188
    environment:
      SERVICE_PRECONDITION: "namenode:9870 datanode:9864"
    volumes:
      - /data/container_data/historyserver:/hadoop/yarn/timeline
    env_file:
      - ./hadoop.env

  hiveserver:
    image: hoaln/hadoop-hiveserver:3.2.2-java8
    container_name: hiveserver
    hostname: hiveserver
    # restart: always
    networks:
      frontend:
        ipv4_address: 172.20.0.11
    ports:
      - 10000:10000
      - 10002:10002
      - 9083:9083
    # environment:
      # SERVICE_PRECONDITION: "namenode:9870 metastore:5432 resourcemanager:8088 historyserver:8188"
      # SERVICE_PRECONDITION: "namenode:9870 metastore:5432 historyserver:8188"
    env_file:
      - ./hadoop.env

  metastore:
    image: postgres:15
    container_name: metastore
    networks:
      frontend:
        ipv4_address: 172.20.0.12
    ports:
      - 5432:5432
    volumes:
      - /data/container_data/postgres:/var/lib/postgresql/data/pgdata
    environment:
      POSTGRES_PASSWORD: "hive"
      POSTGRES_USER: "hive"
      POSTGRES_DB: "hive"
      PGDATA: "/var/lib/postgresql/data/pgdata"

  hue:
    image: gethue/hue:4.6.0
    container_name: hue
    networks:
      frontend:
        ipv4_address: 172.20.0.13
    ports:
      - 8888:8888  # WebUI
    depends_on:
      - namenode
    volumes:
      - ./conf/hue.ini:/usr/share/hue/desktop/conf/z-hue.ini
    environment:
      SERVICE_PRECONDITION: "namenode:9870 metastore:5432 resourcemanager:8088 historyserver:8188 hiveserver:10000 huedb:5432"
    env_file:
      - ./hadoop.env

  huedb:
    image: postgres:13
    container_name: huedb
    hostname: huedb
    networks:
      frontend:
        ipv4_address: 172.20.0.14
    volumes:
      - ./data/container_data/pg_data:/var/lib/postgresl/data/
    ports:
      - "5433:5432"
    environment:
      POSTGRES_PASSWORD: "hue"
      POSTGRES_USER: "hue"
      POSTGRES_DB: "hue"
      # POSTGRES_PORT: 5433.

networks:
  frontend:
    ipam:
      config:
        - subnet: 172.20.0.0/24